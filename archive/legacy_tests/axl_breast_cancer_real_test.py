#!/usr/bin/env python3
"""
OmniTarget Pipeline: AXL Breast Cancer Hypothesis Testing

Real-world implementation using the developed OmniTarget framework.
Tests AXL inhibition hypothesis with actual MCP server data.
"""

import asyncio
import logging
import time
import json
import numpy as np
import networkx as nx
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Import OmniTarget MCP clients
from src.mcp_clients.kegg_client import KEGGClient
from src.mcp_clients.reactome_client import ReactomeClient
from src.mcp_clients.string_client import STRINGClient
from src.mcp_clients.hpa_client import HPAClient

# Import OmniTarget core components
from src.core.simulation.mra_simulator import MRASimulator
from src.core.simulation.simple_simulator import SimplePerturbationSimulator
from src.core.data_standardizer import DataStandardizer
from src.core.validation import DataValidator

@dataclass
class AnalysisConfig:
    """Configuration for AXL breast cancer analysis."""
    # Target specification
    primary_target: str = "AXL"
    downstream_targets: List[str] = None
    tissue_context: str = "breast"
    cancer_type: str = "breast cancer"
    
    # Network parameters
    string_confidence_threshold: int = 400
    string_add_nodes: int = 10
    species_id: int = 9606  # Human
    
    # Simulation parameters
    perturbation_strength: float = 0.9  # 90% inhibition
    matrix_regularization: float = 0.01
    
    # Performance targets
    max_analysis_time: int = 300  # 5 minutes
    max_memory_mb: int = 2048  # 2GB
    
    def __post_init__(self):
        if self.downstream_targets is None:
            self.downstream_targets = [
                "RELA", "VEGFA", "MMP9", "AKT1", "STAT3", 
                "CCND1", "MAPK14", "MAPK1", "MAPK3", "CASP3"
            ]

class AXLBreastCancerAnalysis:
    """Complete AXL breast cancer hypothesis testing using OmniTarget pipeline."""
    
    def __init__(self, config: AnalysisConfig = None):
        self.config = config or AnalysisConfig()
        self.results = {}
        
        # Load MCP server configurations
        with open('config/mcp_servers.json', 'r') as f:
            self.server_configs = json.load(f)
        
        # Initialize MCP clients
        self.kegg = KEGGClient(self.server_configs['kegg']['path'])
        self.reactome = ReactomeClient(self.server_configs['reactome']['path'])
        self.string = STRINGClient(self.server_configs['string']['path'])
        self.hpa = HPAClient(self.server_configs['hpa']['path'])
        
        # Initialize OmniTarget components
        self.standardizer = DataStandardizer()
        self.validator = DataValidator()
        
        # Analysis state
        self.network = None
        self.simulation_results = None
        self.validation_results = None
    
    async def run_complete_analysis(self) -> Dict[str, Any]:
        """Execute complete AXL breast cancer hypothesis testing."""
        logger.info("üß¨ Starting AXL Breast Cancer Hypothesis Testing")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        try:
            # PHASE 1: Target Characterization
            logger.info("üìã PHASE 1: Target Characterization")
            target_data = await self._phase1_target_characterization()
            
            # PHASE 2: Breast Cancer Network Construction
            logger.info("üè• PHASE 2: Breast Cancer Network Construction")
            network_data = await self._phase2_network_construction(target_data)
            
            # PHASE 3: MRA Perturbation Simulation
            logger.info("‚ö° PHASE 3: MRA Perturbation Simulation")
            simulation_data = await self._phase3_mra_simulation(network_data)
            
            # PHASE 4: Validation and Reporting
            logger.info("üî¨ PHASE 4: Validation and Reporting")
            validation_data = await self._phase4_validation_reporting(simulation_data)
            
            # Compile final results
            self.results = {
                "hypothesis": "AXL inhibition disrupts oncogenic signaling in breast cancer",
                "analysis_metadata": {
                    "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                    "analysis_duration": time.time() - start_time,
                    "pipeline_version": "OmniTarget v1.0",
                    "data_sources": ["KEGG", "Reactome", "STRING", "HPA"]
                },
                "target_characterization": target_data,
                "network_construction": network_data,
                "simulation_results": simulation_data,
                "validation_results": validation_data
            }
            
            logger.info("‚úÖ AXL Breast Cancer Analysis Complete!")
            logger.info(f"‚è±Ô∏è  Total analysis time: {time.time() - start_time:.2f} seconds")
            
            return self.results
            
        except Exception as e:
            logger.error(f"‚ùå Analysis failed: {e}")
            raise
        finally:
            # Cleanup MCP connections
            await self._cleanup_connections()
    
    async def _phase1_target_characterization(self) -> Dict[str, Any]:
        """PHASE 1: Characterize AXL across all 4 databases."""
        logger.info("üîç Step 1.1: Resolving AXL identifiers across databases")
        
        # Start all MCP servers
        await asyncio.gather(
            self.kegg.start(),
            self.reactome.start(),
            self.string.start(),
            self.hpa.start()
        )
        
        target_data = {
            "primary_target": {},
            "downstream_targets": {},
            "pathway_memberships": {},
            "cross_database_consistency": {}
        }
        
        # Resolve AXL across databases
        axl_identifiers = {}
        
        try:
            # KEGG resolution
            logger.info("üîç Resolving AXL in KEGG...")
            kegg_result = await self.kegg.search_genes(self.config.primary_target)
            if kegg_result.get('entries'):
                axl_identifiers['kegg_id'] = kegg_result['entries'][0]['id']
                logger.info(f"‚úÖ KEGG AXL ID: {axl_identifiers['kegg_id']}")
            else:
                logger.warning("‚ö†Ô∏è  AXL not found in KEGG")
            
            # STRING resolution
            logger.info("üîç Resolving AXL in STRING...")
            string_result = await self.string.search_proteins(self.config.primary_target, species=self.config.species_id)
            if string_result.get('proteins'):
                axl_identifiers['string_id'] = string_result['proteins'][0]['string_id']
                logger.info(f"‚úÖ STRING AXL ID: {axl_identifiers['string_id']}")
            else:
                logger.warning("‚ö†Ô∏è  AXL not found in STRING")
            
            # HPA resolution
            logger.info("üîç Resolving AXL in HPA...")
            hpa_result = await self.hpa.search_proteins(self.config.primary_target)
            if hpa_result.get('proteins'):
                axl_identifiers['hpa_id'] = hpa_result['proteins'][0]['protein_id']
                logger.info(f"‚úÖ HPA AXL ID: {axl_identifiers['hpa_id']}")
            else:
                logger.warning("‚ö†Ô∏è  AXL not found in HPA")
            
            # Reactome resolution
            logger.info("üîç Resolving AXL in Reactome...")
            reactome_result = await self.reactome.find_pathways_by_gene(self.config.primary_target)
            if reactome_result.get('pathways'):
                axl_identifiers['reactome_pathways'] = len(reactome_result['pathways'])
                logger.info(f"‚úÖ Reactome AXL pathways: {axl_identifiers['reactome_pathways']}")
            else:
                logger.warning("‚ö†Ô∏è  AXL not found in Reactome")
            
        except Exception as e:
            logger.error(f"‚ùå AXL resolution failed: {e}")
            raise
        
        target_data["primary_target"] = {
            "gene_symbol": self.config.primary_target,
            "identifiers": axl_identifiers,
            "resolution_status": "success" if len(axl_identifiers) >= 2 else "partial"
        }
        
        # Resolve downstream targets
        logger.info("üîç Step 1.2: Resolving downstream targets")
        downstream_data = {}
        
        for target in self.config.downstream_targets:
            logger.info(f"üîç Resolving {target}...")
            target_identifiers = {}
            
            try:
                # KEGG
                kegg_result = await self.kegg.search_genes(target)
                if kegg_result.get('entries'):
                    target_identifiers['kegg_id'] = kegg_result['entries'][0]['id']
                
                # STRING
                string_result = await self.string.search_proteins(target, species=self.config.species_id)
                if string_result.get('proteins'):
                    target_identifiers['string_id'] = string_result['proteins'][0]['string_id']
                
                # HPA
                hpa_result = await self.hpa.search_proteins(target)
                if hpa_result.get('proteins'):
                    target_identifiers['hpa_id'] = hpa_result['proteins'][0]['protein_id']
                
                downstream_data[target] = {
                    "identifiers": target_identifiers,
                    "resolution_status": "success" if len(target_identifiers) >= 2 else "partial"
                }
                
                logger.info(f"‚úÖ {target}: {len(target_identifiers)} databases")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  {target} resolution failed: {e}")
                downstream_data[target] = {
                    "identifiers": {},
                    "resolution_status": "failed",
                    "error": str(e)
                }
        
        target_data["downstream_targets"] = downstream_data
        
        # Query pathway memberships
        logger.info("üîç Step 1.3: Querying pathway memberships")
        pathway_data = await self._query_pathway_memberships(target_data)
        target_data["pathway_memberships"] = pathway_data
        
        # Validate cross-database consistency
        logger.info("üîç Step 1.4: Validating cross-database consistency")
        consistency_data = await self._validate_cross_database_consistency(target_data)
        target_data["cross_database_consistency"] = consistency_data
        
        logger.info("‚úÖ Phase 1 Complete: Target characterization finished")
        return target_data
    
    async def _query_pathway_memberships(self, target_data: Dict[str, Any]) -> Dict[str, Any]:
        """Query pathway memberships for all targets."""
        pathway_data = {
            "kegg_pathways": {},
            "reactome_pathways": {},
            "pathway_hierarchy": {}
        }
        
        all_targets = [self.config.primary_target] + self.config.downstream_targets
        
        for target in all_targets:
            if target_data.get("downstream_targets", {}).get(target, {}).get("resolution_status") == "failed":
                continue
            
            logger.info(f"üîç Querying pathways for {target}...")
            
            # KEGG pathways
            try:
                if target_data.get("primary_target", {}).get("identifiers", {}).get("kegg_id"):
                    kegg_id = target_data["primary_target"]["identifiers"]["kegg_id"]
                elif target_data.get("downstream_targets", {}).get(target, {}).get("identifiers", {}).get("kegg_id"):
                    kegg_id = target_data["downstream_targets"][target]["identifiers"]["kegg_id"]
                else:
                    kegg_id = None
                
                if kegg_id:
                    pathway_result = await self.kegg.find_related_entries(kegg_id, database='pathway')
                    pathway_data["kegg_pathways"][target] = pathway_result.get('pathways', [])
                    logger.info(f"‚úÖ {target} KEGG pathways: {len(pathway_result.get('pathways', []))}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  KEGG pathways for {target} failed: {e}")
                pathway_data["kegg_pathways"][target] = []
            
            # Reactome pathways
            try:
                reactome_result = await self.reactome.find_pathways_by_gene(target)
                pathway_data["reactome_pathways"][target] = reactome_result.get('pathways', [])
                logger.info(f"‚úÖ {target} Reactome pathways: {len(reactome_result.get('pathways', []))}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Reactome pathways for {target} failed: {e}")
                pathway_data["reactome_pathways"][target] = []
        
        return pathway_data
    
    async def _validate_cross_database_consistency(self, target_data: Dict[str, Any]) -> Dict[str, Any]:
        """Validate cross-database consistency of pathway assignments."""
        consistency_data = {
            "total_targets": len(self.config.downstream_targets) + 1,
            "resolved_targets": 0,
            "pathway_consistency": {},
            "overall_consistency_score": 0.0
        }
        
        # Count resolved targets
        resolved_count = 0
        if target_data.get("primary_target", {}).get("resolution_status") == "success":
            resolved_count += 1
        
        for target_data_item in target_data.get("downstream_targets", {}).values():
            if target_data_item.get("resolution_status") == "success":
                resolved_count += 1
        
        consistency_data["resolved_targets"] = resolved_count
        consistency_data["overall_consistency_score"] = resolved_count / (len(self.config.downstream_targets) + 1)
        
        logger.info(f"‚úÖ Cross-database consistency: {resolved_count}/{len(self.config.downstream_targets) + 1} targets resolved")
        
        return consistency_data
    
    async def _phase2_network_construction(self, target_data: Dict[str, Any]) -> Dict[str, Any]:
        """PHASE 2: Build AXL-centered interaction network with breast cancer context."""
        logger.info("üîç Step 2.1: Building STRING protein-protein interaction network")
        
        # Get all target genes for network
        all_targets = [self.config.primary_target] + self.config.downstream_targets
        
        # Build STRING interaction network
        try:
            string_network = await self.string.get_interaction_network(
                genes=all_targets,
                species=self.config.species_id,
                required_score=self.config.string_confidence_threshold,
                add_nodes=self.config.string_add_nodes
            )
            
            logger.info(f"‚úÖ STRING network: {len(string_network.get('nodes', []))} nodes, {len(string_network.get('edges', []))} edges")
            
        except Exception as e:
            logger.error(f"‚ùå STRING network construction failed: {e}")
            raise
        
        # Parse STRING interaction evidence
        logger.info("üîç Step 2.2: Parsing STRING interaction evidence")
        interaction_evidence = self._parse_string_evidence(string_network)
        
        # Overlay HPA breast tissue expression
        logger.info("üîç Step 2.3: Overlaying HPA breast tissue expression")
        expression_data = await self._get_hpa_expression_data(all_targets)
        
        # Identify breast cancer markers
        logger.info("üîç Step 2.4: Identifying breast cancer markers")
        cancer_markers = await self._identify_cancer_markers(all_targets)
        
        # Build NetworkX graph
        logger.info("üîç Step 2.5: Building NetworkX graph")
        network_graph = self._build_networkx_graph(string_network, expression_data, cancer_markers)
        
        network_data = {
            "string_network": string_network,
            "interaction_evidence": interaction_evidence,
            "expression_data": expression_data,
            "cancer_markers": cancer_markers,
            "network_graph": {
                "nodes": list(network_graph.nodes()),
                "edges": list(network_graph.edges()),
                "node_count": network_graph.number_of_nodes(),
                "edge_count": network_graph.number_of_edges(),
                "density": nx.density(network_graph)
            }
        }
        
        # Validation criteria
        validation_results = self._validate_network_construction(network_data)
        network_data["validation"] = validation_results
        
        logger.info("‚úÖ Phase 2 Complete: Network construction finished")
        return network_data
    
    def _parse_string_evidence(self, string_network: Dict[str, Any]) -> Dict[str, Any]:
        """Parse STRING interaction evidence."""
        evidence_data = {
            "high_confidence_edges": 0,
            "evidence_types": {},
            "confidence_distribution": {}
        }
        
        edges = string_network.get('edges', [])
        for edge in edges:
            confidence = edge.get('combined_score', 0)
            if confidence >= 700:
                evidence_data["high_confidence_edges"] += 1
            
            # Parse evidence types
            for evidence_type in ['experimental', 'database', 'coexpression', 'textmining']:
                if evidence_type in edge:
                    if evidence_type not in evidence_data["evidence_types"]:
                        evidence_data["evidence_types"][evidence_type] = 0
                    evidence_data["evidence_types"][evidence_type] += 1
        
        logger.info(f"‚úÖ Evidence parsing: {evidence_data['high_confidence_edges']} high-confidence edges")
        return evidence_data
    
    async def _get_hpa_expression_data(self, targets: List[str]) -> Dict[str, Any]:
        """Get HPA expression data for targets."""
        expression_data = {}
        
        for target in targets:
            try:
                # Get tissue expression
                tissue_expr = await self.hpa.get_tissue_expression(gene_symbol=target)
                expression_data[target] = {
                    "tissue_expression": tissue_expr,
                    "breast_expression": self._extract_breast_expression(tissue_expr)
                }
                
                # Get pathology data
                pathology_data = await self.hpa.get_pathology_data(gene_symbols=[target])
                expression_data[target]["pathology"] = pathology_data
                
                logger.info(f"‚úÖ {target} expression data retrieved")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  HPA expression for {target} failed: {e}")
                expression_data[target] = {
                    "tissue_expression": None,
                    "breast_expression": None,
                    "pathology": None
                }
        
        return expression_data
    
    def _extract_breast_expression(self, tissue_data: Dict[str, Any]) -> Optional[float]:
        """Extract breast tissue expression level."""
        if not tissue_data or not tissue_data.get('tissues'):
            return None
        
        for tissue in tissue_data['tissues']:
            if 'breast' in tissue.get('tissue_name', '').lower():
                return tissue.get('expression_level', 0)
        
        return None
    
    async def _identify_cancer_markers(self, targets: List[str]) -> Dict[str, Any]:
        """Identify breast cancer markers."""
        cancer_markers = {}
        
        for target in targets:
            try:
                # Search for cancer markers
                marker_result = await self.hpa.search_cancer_markers(
                    cancer_type=self.config.cancer_type,
                    gene_symbol=target
                )
                
                cancer_markers[target] = {
                    "is_marker": len(marker_result.get('markers', [])) > 0,
                    "marker_data": marker_result
                }
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Cancer marker search for {target} failed: {e}")
                cancer_markers[target] = {
                    "is_marker": False,
                    "marker_data": None
                }
        
        return cancer_markers
    
    def _build_networkx_graph(self, string_network: Dict[str, Any], 
                            expression_data: Dict[str, Any], 
                            cancer_markers: Dict[str, Any]) -> nx.Graph:
        """Build NetworkX graph from STRING data."""
        G = nx.Graph()
        
        # Add nodes with attributes
        for node in string_network.get('nodes', []):
            node_name = node.get('name', node.get('id'))
            G.add_node(node_name)
            
            # Add expression data
            if node_name in expression_data:
                G.nodes[node_name]['expression'] = expression_data[node_name].get('breast_expression')
                G.nodes[node_name]['pathology'] = expression_data[node_name].get('pathology')
            
            # Add cancer marker status
            if node_name in cancer_markers:
                G.nodes[node_name]['is_cancer_marker'] = cancer_markers[node_name]['is_marker']
        
        # Add edges with weights
        for edge in string_network.get('edges', []):
            source = edge.get('source')
            target = edge.get('target')
            confidence = edge.get('combined_score', 0)
            
            if source and target:
                G.add_edge(source, target, 
                          weight=confidence / 1000,  # Normalize to 0-1
                          confidence=confidence)
        
        return G
    
    def _validate_network_construction(self, network_data: Dict[str, Any]) -> Dict[str, Any]:
        """Validate network construction criteria."""
        validation = {
            "contains_all_targets": True,
            "string_confidence_met": True,
            "hpa_expression_coverage": 0.0,
            "validation_passed": True
        }
        
        # Check if all targets are in network
        network_nodes = set(network_data["network_graph"]["nodes"])
        all_targets = set([self.config.primary_target] + self.config.downstream_targets)
        missing_targets = all_targets - network_nodes
        
        if missing_targets:
            validation["contains_all_targets"] = False
            validation["missing_targets"] = list(missing_targets)
            logger.warning(f"‚ö†Ô∏è  Missing targets in network: {missing_targets}")
        
        # Check STRING confidence
        edges = network_data["string_network"].get('edges', [])
        high_confidence_edges = [e for e in edges if e.get('combined_score', 0) >= self.config.string_confidence_threshold]
        confidence_ratio = len(high_confidence_edges) / len(edges) if edges else 0
        
        if confidence_ratio < 0.8:
            validation["string_confidence_met"] = False
            logger.warning(f"‚ö†Ô∏è  Low STRING confidence: {confidence_ratio:.2f}")
        
        # Check HPA expression coverage
        expression_targets = [t for t, data in network_data["expression_data"].items() 
                            if data.get('breast_expression') is not None]
        validation["hpa_expression_coverage"] = len(expression_targets) / len(all_targets)
        
        if validation["hpa_expression_coverage"] < 0.8:
            logger.warning(f"‚ö†Ô∏è  Low HPA expression coverage: {validation['hpa_expression_coverage']:.2f}")
        
        validation["validation_passed"] = all([
            validation["contains_all_targets"],
            validation["string_confidence_met"],
            validation["hpa_expression_coverage"] >= 0.8
        ])
        
        return validation
    
    async def _phase3_mra_simulation(self, network_data: Dict[str, Any]) -> Dict[str, Any]:
        """PHASE 3: Simulate 90% AXL inhibition using MRA."""
        logger.info("üîç Step 3.1: Constructing local response coefficient matrix")
        
        # Build NetworkX graph from network data
        G = nx.Graph()
        
        # Add nodes
        for node in network_data["network_graph"]["nodes"]:
            G.add_node(node)
        
        # Add edges with weights
        for edge in network_data["string_network"]["edges"]:
            source = edge.get('source')
            target = edge.get('target')
            confidence = edge.get('combined_score', 0)
            
            if source and target:
                G.add_edge(source, target, weight=confidence / 1000)
        
        # Construct response matrix
        logger.info("üîç Step 3.2: Building response coefficient matrix")
        response_matrix = self._construct_response_matrix(G, network_data)
        
        # Initialize perturbation vector
        logger.info("üîç Step 3.3: Computing MRA simulation")
        perturbation_vector = self._create_perturbation_vector(G)
        
        # Compute steady-state using MRA
        node_effects = self._compute_mra_effects(response_matrix, perturbation_vector, G)
        
        # Classify affected nodes
        logger.info("üîç Step 3.4: Classifying affected nodes")
        node_classification = self._classify_affected_nodes(G, node_effects)
        
        # Extract pathway-level impacts
        logger.info("üîç Step 3.5: Computing pathway-level impacts")
        pathway_impacts = self._compute_pathway_impacts(node_effects, network_data)
        
        simulation_data = {
            "response_matrix": response_matrix.tolist(),
            "perturbation_vector": perturbation_vector.tolist(),
            "node_effects": node_effects,
            "node_classification": node_classification,
            "pathway_impacts": pathway_impacts,
            "simulation_parameters": {
                "perturbation_strength": self.config.perturbation_strength,
                "matrix_regularization": self.config.matrix_regularization,
                "target_node": self.config.primary_target
            }
        }
        
        logger.info("‚úÖ Phase 3 Complete: MRA simulation finished")
        return simulation_data
    
    def _construct_response_matrix(self, G: nx.Graph, network_data: Dict[str, Any]) -> np.ndarray:
        """Construct local response coefficient matrix."""
        nodes = list(G.nodes())
        n = len(nodes)
        R = np.zeros((n, n))
        
        # Create node index mapping
        node_to_idx = {node: i for i, node in enumerate(nodes)}
        
        # Fill matrix with interaction strengths
        for edge in G.edges(data=True):
            source, target, data = edge
            weight = data.get('weight', 0)
            
            if source in node_to_idx and target in node_to_idx:
                i, j = node_to_idx[source], node_to_idx[target]
                R[i, j] = weight
                R[j, i] = weight  # Symmetric
        
        # Apply pathway context modifiers
        R = self._apply_pathway_modifiers(R, nodes, network_data)
        
        # Apply expression modifiers
        R = self._apply_expression_modifiers(R, nodes, network_data)
        
        return R
    
    def _apply_pathway_modifiers(self, R: np.ndarray, nodes: List[str], 
                               network_data: Dict[str, Any]) -> np.ndarray:
        """Apply pathway context modifiers."""
        # Get pathway memberships
        pathway_memberships = {}
        for target, pathways in network_data.get("pathway_memberships", {}).get("kegg_pathways", {}).items():
            pathway_memberships[target] = [p.get('id', '') for p in pathways]
        
        # Apply modifiers
        for i, node_i in enumerate(nodes):
            for j, node_j in enumerate(nodes):
                if i != j and R[i, j] > 0:
                    # Check if nodes are in same pathway
                    pathways_i = pathway_memberships.get(node_i, [])
                    pathways_j = pathway_memberships.get(node_j, [])
                    
                    if any(p in pathways_j for p in pathways_i):
                        R[i, j] *= 1.2  # Same pathway: 1.2x
                    else:
                        R[i, j] *= 0.4  # Different pathway: 0.4x
        
        return R
    
    def _apply_expression_modifiers(self, R: np.ndarray, nodes: List[str], 
                                  network_data: Dict[str, Any]) -> np.ndarray:
        """Apply expression-based modifiers."""
        expression_data = network_data.get("expression_data", {})
        
        for i, node in enumerate(nodes):
            if node in expression_data:
                breast_expr = expression_data[node].get('breast_expression')
                if breast_expr is not None:
                    # Scale interactions based on expression level
                    expr_factor = min(2.0, max(0.1, breast_expr / 10.0))  # Normalize expression
                    R[i, :] *= expr_factor
                    R[:, i] *= expr_factor
        
        return R
    
    def _create_perturbation_vector(self, G: nx.Graph) -> np.ndarray:
        """Create perturbation vector for AXL inhibition."""
        nodes = list(G.nodes())
        perturbation = np.zeros(len(nodes))
        
        if self.config.primary_target in nodes:
            axl_idx = nodes.index(self.config.primary_target)
            perturbation[axl_idx] = -self.config.perturbation_strength
        
        return perturbation
    
    def _compute_mra_effects(self, R: np.ndarray, perturbation: np.ndarray, G: nx.Graph) -> Dict[str, float]:
        """Compute MRA effects using matrix inversion."""
        nodes = list(G.nodes())
        n = len(nodes)
        
        # Add regularization to avoid singular matrices
        I = np.eye(n)
        regularized_R = R + self.config.matrix_regularization * I
        
        try:
            # Compute global response: (I - R)^-1 √ó perturbation
            global_response = np.linalg.solve(I - regularized_R, perturbation)
            
            # Convert to dictionary
            node_effects = {nodes[i]: float(global_response[i]) for i in range(n)}
            
            logger.info(f"‚úÖ MRA computation successful: {len(node_effects)} node effects")
            
        except np.linalg.LinAlgError as e:
            logger.warning(f"‚ö†Ô∏è  Matrix inversion failed, using approximation: {e}")
            # Fallback: use iterative approximation
            global_response = self._iterative_mra_solver(regularized_R, perturbation)
            node_effects = {nodes[i]: float(global_response[i]) for i in range(n)}
        
        return node_effects
    
    def _iterative_mra_solver(self, R: np.ndarray, perturbation: np.ndarray, 
                            max_iterations: int = 100) -> np.ndarray:
        """Iterative solver for MRA when matrix inversion fails."""
        n = len(perturbation)
        x = perturbation.copy()
        
        for i in range(max_iterations):
            x_new = perturbation + R @ x
            if np.allclose(x, x_new, rtol=1e-6):
                break
            x = x_new
        
        return x
    
    def _classify_affected_nodes(self, G: nx.Graph, node_effects: Dict[str, float]) -> Dict[str, Any]:
        """Classify affected nodes by effect type."""
        classification = {
            "direct_targets": [],
            "downstream_targets": [],
            "upstream_targets": [],
            "unaffected": []
        }
        
        axl_node = self.config.primary_target
        
        for node, effect in node_effects.items():
            if node == axl_node:
                continue
            
            if abs(effect) < 0.01:  # Threshold for "unaffected"
                classification["unaffected"].append(node)
            elif effect < 0:
                # Check if directly connected to AXL
                if G.has_edge(axl_node, node):
                    classification["direct_targets"].append(node)
                else:
                    classification["downstream_targets"].append(node)
            else:
                classification["upstream_targets"].append(node)
        
        return classification
    
    def _compute_pathway_impacts(self, node_effects: Dict[str, float], 
                               network_data: Dict[str, Any]) -> Dict[str, Any]:
        """Compute pathway-level impacts."""
        pathway_impacts = {
            "survival_signaling": {
                "components": ["AKT1", "RELA", "STAT3"],
                "effects": {},
                "average_effect": 0.0
            },
            "proliferation": {
                "components": ["CCND1", "MAPK1", "MAPK3"],
                "effects": {},
                "average_effect": 0.0
            },
            "invasion_metastasis": {
                "components": ["MMP9", "VEGFA"],
                "effects": {},
                "average_effect": 0.0
            },
            "apoptosis": {
                "components": ["CASP3"],
                "effects": {},
                "average_effect": 0.0
            }
        }
        
        for pathway, data in pathway_impacts.items():
            effects = []
            for component in data["components"]:
                if component in node_effects:
                    effect = node_effects[component]
                    data["effects"][component] = effect
                    effects.append(effect)
            
            if effects:
                data["average_effect"] = sum(effects) / len(effects)
        
        return pathway_impacts
    
    async def _phase4_validation_reporting(self, simulation_data: Dict[str, Any]) -> Dict[str, Any]:
        """PHASE 4: Validate predictions and generate report."""
        logger.info("üîç Step 4.1: Comparing predictions with literature")
        
        # Literature-reported effects for validation
        literature_effects = {
            "AKT1": -0.8,   # pAKT decreases
            "RELA": -0.75,  # NF-Œ∫B decreases
            "MAPK1": -0.6,   # pERK decreases
            "MAPK3": -0.6,   # pERK decreases
            "MMP9": -0.85,   # MMP9 strongly suppressed
            "VEGFA": -0.65,  # VEGF decreases
            "CCND1": -0.6,   # Cyclin D1 decreases
            "STAT3": -0.5,   # pSTAT3 decreases
            "MAPK14": -0.4,  # p38 decreases
            "CASP3": 0.7     # Caspase-3 increases
        }
        
        # Compare predictions with literature
        validation_results = {
            "target_agreement": {},
            "direction_agreement": 0.0,
            "magnitude_correlation": 0.0,
            "biological_plausibility": True,
            "validation_metrics": {}
        }
        
        node_effects = simulation_data.get("node_effects", {})
        agreements = []
        magnitudes_pred = []
        magnitudes_lit = []
        
        for target, lit_effect in literature_effects.items():
            if target in node_effects:
                pred_effect = node_effects[target]
                
                # Direction agreement
                direction_match = (pred_effect < 0 and lit_effect < 0) or (pred_effect > 0 and lit_effect > 0)
                agreements.append(direction_match)
                
                # Magnitude correlation
                magnitudes_pred.append(pred_effect)
                magnitudes_lit.append(lit_effect)
                
                validation_results["target_agreement"][target] = {
                    "predicted": pred_effect,
                    "literature": lit_effect,
                    "direction_match": direction_match,
                    "magnitude_difference": abs(pred_effect - lit_effect)
                }
        
        # Calculate metrics
        validation_results["direction_agreement"] = sum(agreements) / len(agreements) if agreements else 0
        validation_results["magnitude_correlation"] = np.corrcoef(magnitudes_pred, magnitudes_lit)[0, 1] if len(magnitudes_pred) > 1 else 0
        
        # Biological plausibility check
        pathway_impacts = simulation_data.get("pathway_impacts", {})
        survival_effect = pathway_impacts.get("survival_signaling", {}).get("average_effect", 0)
        apoptosis_effect = pathway_impacts.get("apoptosis", {}).get("average_effect", 0)
        
        validation_results["biological_plausibility"] = (
            survival_effect < -0.3 and  # Survival signaling suppressed
            apoptosis_effect > 0.3      # Apoptosis induced
        )
        
        validation_results["validation_metrics"] = {
            "direction_agreement_rate": validation_results["direction_agreement"],
            "magnitude_correlation": validation_results["magnitude_correlation"],
            "biological_plausibility": validation_results["biological_plausibility"],
            "overall_validation_score": (
                validation_results["direction_agreement"] * 0.4 +
                abs(validation_results["magnitude_correlation"]) * 0.3 +
                (1.0 if validation_results["biological_plausibility"] else 0.0) * 0.3
            )
        }
        
        logger.info("‚úÖ Phase 4 Complete: Validation and reporting finished")
        return validation_results
    
    async def _cleanup_connections(self):
        """Cleanup MCP server connections."""
        try:
            await asyncio.gather(
                self.kegg.stop(),
                self.reactome.stop(),
                self.string.stop(),
                self.hpa.stop(),
                return_exceptions=True
            )
            logger.info("‚úÖ MCP server connections cleaned up")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Cleanup warning: {e}")
    
    def save_results(self, filename: str = "axl_breast_cancer_analysis.json") -> Path:
        """Save analysis results to JSON file."""
        output_path = Path(filename)
        
        with open(output_path, 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        
        logger.info(f"üìÅ Results saved to: {output_path.absolute()}")
        return output_path
    
    def print_summary(self):
        """Print analysis summary."""
        if not self.results:
            print("‚ùå No results available")
            return
        
        print("\n" + "="*80)
        print("üß¨ OMNITARGET PIPELINE - AXL BREAST CANCER ANALYSIS")
        print("="*80)
        
        # Analysis metadata
        metadata = self.results.get("analysis_metadata", {})
        print(f"Analysis Date: {metadata.get('timestamp', 'Unknown')}")
        print(f"Duration: {metadata.get('analysis_duration', 0):.2f} seconds")
        print(f"Data Sources: {', '.join(metadata.get('data_sources', []))}")
        print()
        
        # Target characterization
        target_data = self.results.get("target_characterization", {})
        print("üìã TARGET CHARACTERIZATION:")
        print("-" * 40)
        primary = target_data.get("primary_target", {})
        print(f"AXL Resolution: {primary.get('resolution_status', 'Unknown')}")
        print(f"Databases: {len(primary.get('identifiers', {}))}")
        
        downstream = target_data.get("downstream_targets", {})
        resolved_count = sum(1 for t in downstream.values() if t.get('resolution_status') == 'success')
        print(f"Downstream Targets: {resolved_count}/{len(downstream)} resolved")
        print()
        
        # Network construction
        network_data = self.results.get("network_construction", {})
        print("üè• NETWORK CONSTRUCTION:")
        print("-" * 40)
        network_graph = network_data.get("network_graph", {})
        print(f"Nodes: {network_graph.get('node_count', 0)}")
        print(f"Edges: {network_graph.get('edge_count', 0)}")
        print(f"Density: {network_graph.get('density', 0):.3f}")
        
        validation = network_data.get("validation", {})
        print(f"Validation: {'‚úÖ PASSED' if validation.get('validation_passed') else '‚ùå FAILED'}")
        print()
        
        # Simulation results
        simulation_data = self.results.get("simulation_results", {})
        print("‚ö° SIMULATION RESULTS:")
        print("-" * 40)
        node_effects = simulation_data.get("node_effects", {})
        
        # Show top effects
        sorted_effects = sorted(node_effects.items(), key=lambda x: abs(x[1]), reverse=True)
        for target, effect in sorted_effects[:8]:
            direction = "‚Üë" if effect > 0 else "‚Üì"
            strength = "Strong" if abs(effect) > 0.7 else "Moderate" if abs(effect) > 0.5 else "Weak"
            print(f"{target:8} {direction} {abs(effect):.2f} ({strength})")
        
        # Pathway impacts
        pathway_impacts = simulation_data.get("pathway_impacts", {})
        print("\nüéØ PATHWAY IMPACTS:")
        for pathway, data in pathway_impacts.items():
            avg_effect = data.get("average_effect", 0)
            impact = "Suppressed" if avg_effect < -0.3 else "Induced" if avg_effect > 0.3 else "Minimal"
            print(f"{pathway.replace('_', ' ').title():20} {avg_effect:+.2f} ({impact})")
        print()
        
        # Validation results
        validation_data = self.results.get("validation_results", {})
        print("üî¨ VALIDATION RESULTS:")
        print("-" * 40)
        metrics = validation_data.get("validation_metrics", {})
        print(f"Direction Agreement: {metrics.get('direction_agreement_rate', 0):.1%}")
        print(f"Magnitude Correlation: {metrics.get('magnitude_correlation', 0):.3f}")
        print(f"Biological Plausibility: {'‚úÖ YES' if metrics.get('biological_plausibility') else '‚ùå NO'}")
        print(f"Overall Score: {metrics.get('overall_validation_score', 0):.3f}")
        
        print("="*80)


async def main():
    """Main execution function."""
    print("üß¨ OmniTarget Pipeline: AXL Breast Cancer Hypothesis Testing")
    print("=" * 80)
    print("‚ö†Ô∏è  This will use REAL MCP servers and may take 3-5 minutes")
    print("=" * 80)
    
    # Initialize analysis
    config = AnalysisConfig()
    analysis = AXLBreastCancerAnalysis(config)
    
    try:
        # Run complete analysis
        results = await analysis.run_complete_analysis()
        
        # Print summary
        analysis.print_summary()
        
        # Save results
        output_file = analysis.save_results()
        
        print(f"\n‚úÖ Analysis complete! Results saved to: {output_file}")
        print("üöÄ Ready for experimental validation!")
        
    except Exception as e:
        print(f"‚ùå Analysis failed: {e}")
        logger.exception("Full error details:")
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)
